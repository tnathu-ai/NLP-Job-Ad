{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Milestone I Natural Language Processing\n",
    "## Task 1. Basic Text Pre-processing\n",
    "#### Student Name: XXXX XXXX\n",
    "#### Student ID: 000000\n",
    "\n",
    "Date: XXXX\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3 and Jupyter notebook\n",
    "\n",
    "Libraries used: please include all the libraries you used in your assignment, e.g.,:\n",
    "* pandas\n",
    "* re\n",
    "* numpy\n",
    "\n",
    "## Introduction\n",
    "You should give a brief information of this assessment task here.\n",
    "\n",
    "<span style=\"color: red\"> Note that this is a sample notebook only. You will need to fill in the proper markdown and code blocks. You might also want to make necessary changes to the structure to meet your own needs. Note also that any generic comments written in this notebook are to be removed and replace with your own words.</span>\n",
    "\n",
    "## Dataset\n",
    "\n",
    "+ This is a small collection of job advertisement documents (around 750 jobs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to import libraries as you need in this assessment, e.g.,\n",
    "\n",
    "from sklearn.datasets import load_files   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1 Examining and loading data\n",
    "\n",
    "Before doing any pre-processing, we need to load the data into a proper format. \n",
    "To load the data, you have to explore the data folder. Inside the `data` folder:\n",
    "+ Inside the data folder you will see 4 different subfolders, namely: `Accounting_Finance`, `Engineering`,`Healthcare_Nursing`, and `Sales`, each folder name is a job category.\n",
    "+ The job advertisement text documents of a particular category are located in the corresponding subfolder.\n",
    "+ Each job advertisement document is a txt file, named as \"Job_<ID>.txt\". It contains the title, the webindex,(some will also have information on the company name, some might not), and the full description of the job advertisement. \n",
    "\n",
    "In this case, providing that the dataset is given in a very well organised way, I would use a super handy API [`load_files`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_files.html) from `sklearn.datasets`. \n",
    "    \n",
    "**import the function by:**\n",
    "```python\n",
    "from sklearn.datasets import load_files  \n",
    "```\n",
    "\n",
    "Then you can use the function to directly load the data and labels, for example:\n",
    "```python\n",
    "df = load_files(r\"data\")  \n",
    "```\n",
    "\n",
    "The loaded `movie_data` is then a dictionary, with the following attributes:\n",
    "\n",
    "| **ATTRIBUTES**   | **DESCRIPTION**                                           |\n",
    "|--------------|---------------------------------------------------------------|\n",
    "| Webindex     | 8 digit Id of the job advertisement on the website            |\n",
    "| Title        | Title of the advertised job position                          |\n",
    "| Company      | Company (employer) of the advertised job position             |\n",
    "| Description  | the filenames holding the dataset                             |\n",
    "\n",
    "\n",
    "- Examine the data folder, including the categories and job advertisment txt documents, etc. Explain your findings here, e.g., number of folders and format of txt files, etc.\n",
    "- Load the data into proper data structures and get it ready for processing.\n",
    "- Extract webIndex and description into proper data structures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to inspect the provided data file...\n",
    "df = load_files(r\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Sales",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:117\u001b[0m, in \u001b[0;36mBunch.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Sales'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSales\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:119\u001b[0m, in \u001b[0;36mBunch.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(key)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Sales"
     ]
    }
   ],
   "source": [
    "df.Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Pre-processing data\n",
    "Perform the required text pre-processing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...... Sections and code blocks on basic text pre-processing\n",
    "\n",
    "\n",
    "<span style=\"color: red\"> You might have complex notebook structure in this section, please feel free to create your own notebook structure. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to perform the task..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving required outputs\n",
    "Save the vocabulary, bigrams and job advertisment txt as per spectification.\n",
    "- vocab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to save output data...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Give a short summary and anything you would like to talk about the assessment task here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Couple of notes for all code blocks in this notebook\n",
    "- please provide proper comment on your code\n",
    "- Please re-start and run all cells to make sure codes are runable and include your output in the submission.   \n",
    "<span style=\"color: red\"> This markdown block can be removed once the task is completed. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
