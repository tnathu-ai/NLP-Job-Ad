{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification with Word Embeddings\n",
    "\n",
    "In this previous activity, we have enough fun playinng around the word embeddings. \n",
    "Now, we get to the stage that we will make real use of them, i.e., we are going to build on these embeddings machine learing models for document classification. ðŸ˜Š\n",
    "\n",
    "\n",
    "## The Dataset\n",
    "Same as in the previous activity, the document collection that we are going to use is the BBC News Dataset. For the origin of the dataset, please refer to [here](http://mlg.ucd.ie/datasets/bbc.html)\n",
    "To be brief, the dataset consists of 2225 documents from the BBC news website corresponding to stories in five topical areas, i.e., class Labels (business, entertainment, politics, sport, tech).\n",
    "\n",
    "In this activity, instead of using the raw dataset, we will utilised the pre-processed clean dataset we saved in our previous Activity 3 Generating Feature Vectors.\n",
    "Recall that at the end of Activity 3, we saved the pre-processed articles in a txt file named `bbcNews.txt`, where, each row is a document, with tokens seperated by whitespace.\n",
    "\n",
    "Before continue, please make sure you have the following files in the same folder as this jupyter notebook:\n",
    "* `bbcNews.txt`: contains the pre-process BBC news articles\n",
    "* `labels.csv`: contains the label/class of each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from nltk.probability import *\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# import code as a function\n",
    "from src.utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging for event tracking\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in the labels and article data, and construct a single dataframe to store them correspondingly. \n",
    "Note that the order of the articles are the same as the labels data, as they are all in sorted order of document names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Webindex</th>\n",
       "      <th>Company</th>\n",
       "      <th>Description</th>\n",
       "      <th>Tokenized Description</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;function title at 0x7fd51155e670&gt;</td>\n",
       "      <td>68997528</td>\n",
       "      <td>First Recruitment Services</td>\n",
       "      <td>Accountant (partqualified) to **** p.a. South ...</td>\n",
       "      <td>['accountant', 'partqualified', 'south', 'east...</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;function title at 0x7fd51155e670&gt;</td>\n",
       "      <td>68063513</td>\n",
       "      <td>Austin Andrew Ltd</td>\n",
       "      <td>One of the leading Hedge Funds in London is cu...</td>\n",
       "      <td>['leading', 'hedge', 'funds', 'london', 'recru...</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;function title at 0x7fd51155e670&gt;</td>\n",
       "      <td>68700336</td>\n",
       "      <td>Caritas</td>\n",
       "      <td>An exciting opportunity has arisen to join an ...</td>\n",
       "      <td>['exciting', 'opportunity', 'arisen', 'join', ...</td>\n",
       "      <td>Healthcare_Nursing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Title  Webindex                     Company  \\\n",
       "0  <function title at 0x7fd51155e670>  68997528  First Recruitment Services   \n",
       "1  <function title at 0x7fd51155e670>  68063513           Austin Andrew Ltd   \n",
       "2  <function title at 0x7fd51155e670>  68700336                     Caritas   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Accountant (partqualified) to **** p.a. South ...   \n",
       "1  One of the leading Hedge Funds in London is cu...   \n",
       "2  An exciting opportunity has arisen to join an ...   \n",
       "\n",
       "                               Tokenized Description            Category  \n",
       "0  ['accountant', 'partqualified', 'south', 'east...  Accounting_Finance  \n",
       "1  ['leading', 'hedge', 'funds', 'london', 'recru...  Accounting_Finance  \n",
       "2  ['exciting', 'opportunity', 'arisen', 'join', ...  Healthcare_Nursing  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read job_ad.csv\n",
    "job_ad = pd.read_csv('job_ad.csv')\n",
    "\n",
    "# # get the description of the job ad\n",
    "# description = job_ad['Description']\n",
    "# # get the tokenized description of the job ad\n",
    "# tk_description = job_ad['Tokenized Description']\n",
    "webindex = job_ad['Webindex']\n",
    "\n",
    "\n",
    "# print first 3 rows\n",
    "job_ad.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the article text, and creates another list to store the tokenized version of the article text accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptionFile = './description.txt'\n",
    "with open(descriptionFile) as txtf:\n",
    "    description_txts = txtf.read().splitlines() # reading a list of strings, each for a document/article\n",
    "tk_description = [a.split(' ') for a in description_txts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the article text (as well as the tokenized version) to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_ad['Description'] = description_txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_ad['Tokenized Description'] = tk_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Webindex</th>\n",
       "      <th>Company</th>\n",
       "      <th>Description</th>\n",
       "      <th>Tokenized Description</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>&lt;function title at 0x7fd51155e670&gt;</td>\n",
       "      <td>71186393</td>\n",
       "      <td>Q Personnel Employment Services</td>\n",
       "      <td>working partnership large number equipment man...</td>\n",
       "      <td>[working, partnership, large, number, equipmen...</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>&lt;function title at 0x7fd51155e670&gt;</td>\n",
       "      <td>70623750</td>\n",
       "      <td>Green Care Management</td>\n",
       "      <td>staff nurse newly qualified considered stevena...</td>\n",
       "      <td>[staff, nurse, newly, qualified, considered, s...</td>\n",
       "      <td>Healthcare_Nursing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>&lt;function title at 0x7fd51155e670&gt;</td>\n",
       "      <td>68537749</td>\n",
       "      <td>MSI Nurses LTD</td>\n",
       "      <td>msi nurses recruit qualified experienced regis...</td>\n",
       "      <td>[msi, nurses, recruit, qualified, experienced,...</td>\n",
       "      <td>Healthcare_Nursing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>&lt;function title at 0x7fd51155e670&gt;</td>\n",
       "      <td>69564390</td>\n",
       "      <td>Mason Blake Ltd</td>\n",
       "      <td>newly created position involve daily interacti...</td>\n",
       "      <td>[newly, created, position, involve, daily, int...</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>&lt;function title at 0x7fd51155e670&gt;</td>\n",
       "      <td>72691163</td>\n",
       "      <td>Finlay James Associates Limited</td>\n",
       "      <td>amazing role years sales experience preferably...</td>\n",
       "      <td>[amazing, role, years, sales, experience, pref...</td>\n",
       "      <td>Sales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title  Webindex  \\\n",
       "479  <function title at 0x7fd51155e670>  71186393   \n",
       "328  <function title at 0x7fd51155e670>  70623750   \n",
       "729  <function title at 0x7fd51155e670>  68537749   \n",
       "650  <function title at 0x7fd51155e670>  69564390   \n",
       "743  <function title at 0x7fd51155e670>  72691163   \n",
       "\n",
       "                             Company  \\\n",
       "479  Q Personnel Employment Services   \n",
       "328            Green Care Management   \n",
       "729                   MSI Nurses LTD   \n",
       "650                  Mason Blake Ltd   \n",
       "743  Finlay James Associates Limited   \n",
       "\n",
       "                                           Description  \\\n",
       "479  working partnership large number equipment man...   \n",
       "328  staff nurse newly qualified considered stevena...   \n",
       "729  msi nurses recruit qualified experienced regis...   \n",
       "650  newly created position involve daily interacti...   \n",
       "743  amazing role years sales experience preferably...   \n",
       "\n",
       "                                 Tokenized Description            Category  \n",
       "479  [working, partnership, large, number, equipmen...         Engineering  \n",
       "328  [staff, nurse, newly, qualified, considered, s...  Healthcare_Nursing  \n",
       "729  [msi, nurses, recruit, qualified, experienced,...  Healthcare_Nursing  \n",
       "650  [newly, created, position, involve, daily, int...  Accounting_Finance  \n",
       "743  [amazing, role, years, sales, experience, pref...               Sales  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_ad.sample(n = 5) # look at a few examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous activity, we ahve explore a few language models and word embedings, including: \n",
    "\n",
    "Pre-trained embeddigns:\n",
    "- `preTW2v_wv`: Word2Vec embeddings pre-trained from Google news 300 dataset\n",
    "- `preTGloVe_wv`: pre-trained GloVe embeddings \n",
    "\n",
    "Embeddings trained on the BBC News data:\n",
    "- `bbcW2v_wv`\n",
    "- `bbcFT_wv`\n",
    "\n",
    "In this activity, we are going to use them for document classification. \n",
    "Before we use, we will need to load them in this activity notebook one by one, and for each, we will need to construct the document representation, i.e., document embeddings based on the word embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 null record  ðŸ˜Š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Understand your task by tSNE\n",
    "\n",
    "Alright! so we have the document embedding vector representation for each article now, we can proceed to the task of document classification. \n",
    "Before, we move on, a good habbit is to explore and understand how difficult the task is, whether there are too much noise in the data, making it impossible to clearly separate each category. \n",
    "\n",
    "One way to confirm that the feature space we are using is representative enough for our task (classifying articles into separate labels) to be solvable is to use dimensionality-reduction techniques: These methods project a high-dimensional vector into a lower number of dimensions, with different guarantees on this projection according to the method used. \n",
    "In this activity, we will use [t-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding), a popular dimensionality reduction technique used in many fields, including NLP.\n",
    "\n",
    "Since we will do the same thing again and again when we try other embeddings, we will construct a function to do this again.\n",
    "The following function `plotTSNE` takes the following arugments:\n",
    "* labels, the lable/category of each article\n",
    "* features, a numpy array of document embeddings, each for an article.\n",
    "\n",
    "and projects the feature/document embedding vectors in a 2 dimension space and plot them out. \n",
    "It does the following:\n",
    "1. get the set of classes, called `categories` (5 categories)\n",
    "2. sample 30% of the data/document embeddings randomly, and record the indices selected\n",
    "3. project the selected document embeddings in 2 dimensional space using tSNE, each document embedding now corresponds to a 2 dimensional vector in `projected_features`\n",
    "4. plot them out as scatter plot and highlight different categories in different color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def plotTSNE(labels,features): # features as a numpy array, each element of the array is the document embedding of an article\n",
    "    categories = sorted(labels.unique())\n",
    "    # Sampling a subset of our dataset because t-SNE is computationally expensive\n",
    "    SAMPLE_SIZE = int(len(features) * 0.3)\n",
    "    np.random.seed(0)\n",
    "    indices = np.random.choice(range(len(features)), size=SAMPLE_SIZE, replace=False)\n",
    "    projected_features = TSNE(n_components=2, random_state=0).fit_transform(features[indices])\n",
    "    colors = ['pink', 'green', 'midnightblue', 'orange', 'darkgrey']\n",
    "    for i in range(0,len(categories)):\n",
    "        points = projected_features[(labels[indices] == categories[i])]\n",
    "        plt.scatter(points[:, 0], points[:, 1], s=30, c=colors[i], label=categories[i])\n",
    "    plt.title(\"Feature vector for each article, projected on 2 dimensions.\",\n",
    "              fontdict=dict(fontsize=15))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = preTW2v_dvs.to_numpy() # convert the document vector dataframe to a numpy array\n",
    "plotTSNE(job_ad['Category'],features) # plot the tSNE to have a look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh! Not bad, there are a bit of noises, but overall, seems an easy one, the different categories are quite nicely seperated! Well~ if you remember this dataset prevoiusly, you would have a rough idea anyway, with the binary/count/tfijob_ad vector representation, we have accuracy above 95% ðŸ˜Š\n",
    "Ok, now, let's move on to the serious task: Document Classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FastText model trained on BBC News data\n",
    "\n",
    "Finally, we experiment the FastText embeddings. \n",
    "Similar, we:\n",
    "* load the FastText model saved in our prevoius activity;\n",
    "* generate document embeddings based on the load FastText word embeddings;\n",
    "* explore the reprensentiveness of the features through tSNE;\n",
    "* bulid the logistic regression model based on the generated document embeddings for news classfication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-01 21:45:18,909 : INFO : loading FastText object from bbcFT.model\n",
      "2022-10-01 21:45:18,915 : INFO : loading wv recursively from bbcFT.model.wv.* with mmap=None\n",
      "2022-10-01 21:45:18,915 : INFO : loading vectors_ngrams from bbcFT.model.wv.vectors_ngrams.npy with mmap=None\n",
      "2022-10-01 21:45:19,134 : INFO : setting ignored attribute buckets_word to None\n",
      "2022-10-01 21:45:19,135 : INFO : setting ignored attribute vectors to None\n",
      "2022-10-01 21:45:19,650 : INFO : setting ignored attribute cum_table to None\n",
      "2022-10-01 21:45:19,738 : INFO : FastText lifecycle event {'fname': 'bbcFT.model', 'datetime': '2022-10-01T21:45:19.738783', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  5 2022, 01:53:17) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText<vocab=10485, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "# loading the trained Fasttext model based on bbc News data\n",
    "from gensim.models.fasttext import FastText\n",
    "bbcFT = FastText.load(\"bbcFT.model\")\n",
    "print(bbcFT)\n",
    "bbcFT_wv= bbcFT.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE this can take some time to finish running\n",
    "# generate document embeddings\n",
    "bbcFT_dvs = gen_docVecs(bbcFT_wv,job_ad['Tokenized Description'])\n",
    "bbcFT_dvs.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tnathu-ai/opt/anaconda3/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/tnathu-ai/opt/anaconda3/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# explore feature space\n",
    "features = bbcFT_dvs.to_numpy()\n",
    "plotTSNE(job_ad['Category'],features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "er~~~ for some categories seems a bit messy also....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.311284046692607"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the classfication model and report results\n",
    "seed = 3879312\n",
    "X_train, X_test, y_train, y_test,train_indices,test_indices = train_test_split(bbcFT_dvs, job_ad['Category'], list(range(0,len(job_ad))),test_size=0.33, random_state=seed)\n",
    "\n",
    "model = LogisticRegression(max_iter = 1000,random_state=seed)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generating TF-Ijob_ad weighted document vectors\n",
    "\n",
    "Ok, I hope you have lots of fun building document embeddings based on varoius word embedding models. \n",
    "Previously, when we generate the document embeddings, we just sum up the embeddings vector of each tokenized word in the article, a bit simplicity ðŸ¤”\n",
    "\n",
    "In this section, let's make it a bit more challenging, we are going to build the tf-ijob_ad document embeddings. \n",
    "What does that mean? ðŸ¤¨\n",
    "Hmm~~ it's not magic, we just do a weigthed sum of the word embedding vectors, however, the weight here, refers to the tf-ijob_ad weight of the word. \n",
    "\n",
    "If you already forgot about what is `tf-ijob_ad`, please refer to Activity 3 Pre-processing Text and Generating Features. \n",
    "Otherwise, move on!\n",
    "So we've generated the tf-ijob_ad vector representation of documents in Activity 3 and saved in a txt file called `bbcNews_tVector.txt`. The format of this file is:\n",
    "- each line represents an article;\n",
    "- each line is of the format 'w_index:weight w_index:weight ......' \n",
    "\n",
    "Oh, but we don't have that word index `w_index` here in this activity, what should we do? ðŸ¤”\n",
    "ah ha, we also saved the vocabulary in a file `vocab`, in which each line is a word, and of the format `index,word`. \n",
    "Theresore, based on these two files, we can create a word:weight mapping for each tokenized word in a document!\n",
    "\n",
    "Ok, in the following couple block of codes, this is exactly what we are trying to do, step by step. \n",
    "- the `gen_vocIndex` function reads the the vocabulary file, and create an w_index:word dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aap': 0,\n",
       " 'aaron': 1,\n",
       " 'aat': 2,\n",
       " 'abb': 3,\n",
       " 'abenefit': 4,\n",
       " 'aberdeen': 5,\n",
       " 'abi': 6,\n",
       " 'abilities': 7,\n",
       " 'ability': 8,\n",
       " 'abreast': 9,\n",
       " 'abroad': 10,\n",
       " 'absence': 11,\n",
       " 'absolute': 12,\n",
       " 'ac': 13,\n",
       " 'aca': 14,\n",
       " 'academic': 15,\n",
       " 'academy': 16,\n",
       " 'acca': 17,\n",
       " 'accept': 18,\n",
       " 'acceptable': 19,\n",
       " 'acceptance': 20,\n",
       " 'accepted': 21,\n",
       " 'access': 22,\n",
       " 'accessible': 23,\n",
       " 'accident': 24,\n",
       " 'accommodates': 25,\n",
       " 'accommodation': 26,\n",
       " 'accomplished': 27,\n",
       " 'accordance': 28,\n",
       " 'account': 29,\n",
       " 'accountabilities': 30,\n",
       " 'accountability': 31,\n",
       " 'accountable': 32,\n",
       " 'accountancy': 33,\n",
       " 'accountant': 34,\n",
       " 'accountants': 35,\n",
       " 'accounting': 36,\n",
       " 'accounts': 37,\n",
       " 'accreditation': 38,\n",
       " 'accredited': 39,\n",
       " 'accruals': 40,\n",
       " 'accuracy': 41,\n",
       " 'accurate': 42,\n",
       " 'accurately': 43,\n",
       " 'achievable': 44,\n",
       " 'achieve': 45,\n",
       " 'achieved': 46,\n",
       " 'achievement': 47,\n",
       " 'achievements': 48,\n",
       " 'achiever': 49,\n",
       " 'achieving': 50,\n",
       " 'acii': 51,\n",
       " 'acquired': 52,\n",
       " 'acquisition': 53,\n",
       " 'acquisitions': 54,\n",
       " 'act': 55,\n",
       " 'acting': 56,\n",
       " 'action': 57,\n",
       " 'actions': 58,\n",
       " 'actionscript': 59,\n",
       " 'active': 60,\n",
       " 'actively': 61,\n",
       " 'activites': 62,\n",
       " 'activities': 63,\n",
       " 'activity': 64,\n",
       " 'acts': 65,\n",
       " 'actual': 66,\n",
       " 'actuarial': 67,\n",
       " 'acumen': 68,\n",
       " 'acute': 69,\n",
       " 'ad': 70,\n",
       " 'adam': 71,\n",
       " 'adapt': 72,\n",
       " 'adaptability': 73,\n",
       " 'add': 74,\n",
       " 'added': 75,\n",
       " 'addiction': 76,\n",
       " 'adding': 77,\n",
       " 'addition': 78,\n",
       " 'additional': 79,\n",
       " 'additionally': 80,\n",
       " 'additions': 81,\n",
       " 'address': 82,\n",
       " 'addresses': 83,\n",
       " 'addressing': 84,\n",
       " 'adecco': 85,\n",
       " 'adept': 86,\n",
       " 'adequacy': 87,\n",
       " 'adequate': 88,\n",
       " 'adequately': 89,\n",
       " 'adhere': 90,\n",
       " 'adhered': 91,\n",
       " 'adherence': 92,\n",
       " 'adhering': 93,\n",
       " 'adhoc': 94,\n",
       " 'adjust': 95,\n",
       " 'adjuster': 96,\n",
       " 'adjusting': 97,\n",
       " 'adjustments': 98,\n",
       " 'admin': 99,\n",
       " 'administer': 100,\n",
       " 'administered': 101,\n",
       " 'administering': 102,\n",
       " 'administration': 103,\n",
       " 'administrative': 104,\n",
       " 'administrator': 105,\n",
       " 'administrators': 106,\n",
       " 'admission': 107,\n",
       " 'admissions': 108,\n",
       " 'adobe': 109,\n",
       " 'adolescents': 110,\n",
       " 'adopt': 111,\n",
       " 'adopted': 112,\n",
       " 'adopting': 113,\n",
       " 'adrian': 114,\n",
       " 'ads': 115,\n",
       " 'adstream': 116,\n",
       " 'adult': 117,\n",
       " 'adults': 118,\n",
       " 'advance': 119,\n",
       " 'advanced': 120,\n",
       " 'advancement': 121,\n",
       " 'advances': 122,\n",
       " 'advantage': 123,\n",
       " 'advantageous': 124,\n",
       " 'advert': 125,\n",
       " 'advertise': 126,\n",
       " 'advertised': 127,\n",
       " 'advertisement': 128,\n",
       " 'advertising': 129,\n",
       " 'advertsing': 130,\n",
       " 'advice': 131,\n",
       " 'advise': 132,\n",
       " 'advised': 133,\n",
       " 'adviser': 134,\n",
       " 'advisers': 135,\n",
       " 'advising': 136,\n",
       " 'advisor': 137,\n",
       " 'advisors': 138,\n",
       " 'advisory': 139,\n",
       " 'aeronautical': 140,\n",
       " 'aerospace': 141,\n",
       " 'affairs': 142,\n",
       " 'affect': 143,\n",
       " 'affected': 144,\n",
       " 'affecting': 145,\n",
       " 'affinity': 146,\n",
       " 'affordable': 147,\n",
       " 'africa': 148,\n",
       " 'aftermarket': 149,\n",
       " 'afternoon': 150,\n",
       " 'afternoons': 151,\n",
       " 'age': 152,\n",
       " 'aged': 153,\n",
       " 'agencies': 154,\n",
       " 'agency': 155,\n",
       " 'agent': 156,\n",
       " 'agents': 157,\n",
       " 'ages': 158,\n",
       " 'aggressive': 159,\n",
       " 'agile': 160,\n",
       " 'ago': 161,\n",
       " 'agree': 162,\n",
       " 'agreed': 163,\n",
       " 'agreement': 164,\n",
       " 'agreements': 165,\n",
       " 'agy': 166,\n",
       " 'ahead': 167,\n",
       " 'ahu': 168,\n",
       " 'aid': 169,\n",
       " 'aided': 170,\n",
       " 'aids': 171,\n",
       " 'aim': 172,\n",
       " 'aimed': 173,\n",
       " 'aims': 174,\n",
       " 'air': 175,\n",
       " 'aircraft': 176,\n",
       " 'airdrie': 177,\n",
       " 'alarm': 178,\n",
       " 'alarms': 179,\n",
       " 'albans': 180,\n",
       " 'alcohol': 181,\n",
       " 'aldredirweb': 182,\n",
       " 'alecto': 183,\n",
       " 'alerting': 184,\n",
       " 'alex': 185,\n",
       " 'algorithm': 186,\n",
       " 'algorithms': 187,\n",
       " 'aligned': 188,\n",
       " 'alignment': 189,\n",
       " 'alike': 190,\n",
       " 'allied': 191,\n",
       " 'allocated': 192,\n",
       " 'allocation': 193,\n",
       " 'allowance': 194,\n",
       " 'allowances': 195,\n",
       " 'allowing': 196,\n",
       " 'alm': 197,\n",
       " 'alongside': 198,\n",
       " 'alternate': 199,\n",
       " 'alternative': 200,\n",
       " 'alternatively': 201,\n",
       " 'altrincham': 202,\n",
       " 'aluminium': 203,\n",
       " 'amazing': 204,\n",
       " 'ambassador': 205,\n",
       " 'ambition': 206,\n",
       " 'ambitions': 207,\n",
       " 'ambitious': 208,\n",
       " 'ambridge': 209,\n",
       " 'amenities': 210,\n",
       " 'america': 211,\n",
       " 'american': 212,\n",
       " 'amigo': 213,\n",
       " 'aml': 214,\n",
       " 'amount': 215,\n",
       " 'amounts': 216,\n",
       " 'amp': 217,\n",
       " 'amrywiol': 218,\n",
       " 'anaesthetics': 219,\n",
       " 'anaesthetist': 220,\n",
       " 'analog': 221,\n",
       " 'analogue': 222,\n",
       " 'analyse': 223,\n",
       " 'analysers': 224,\n",
       " 'analyses': 225,\n",
       " 'analysing': 226,\n",
       " 'analysis': 227,\n",
       " 'analyst': 228,\n",
       " 'analystbelfast': 229,\n",
       " 'analysts': 230,\n",
       " 'analytical': 231,\n",
       " 'analytics': 232,\n",
       " 'ancillary': 233,\n",
       " 'andoffers': 234,\n",
       " 'andrew': 235,\n",
       " 'android': 236,\n",
       " 'androidoptometryapp': 237,\n",
       " 'andy': 238,\n",
       " 'angiography': 239,\n",
       " 'anglia': 240,\n",
       " 'annual': 241,\n",
       " 'annum': 242,\n",
       " 'anomalies': 243,\n",
       " 'answer': 244,\n",
       " 'answered': 245,\n",
       " 'answering': 246,\n",
       " 'anthony': 247,\n",
       " 'anticipate': 248,\n",
       " 'anticipated': 249,\n",
       " 'antony': 250,\n",
       " 'apartments': 251,\n",
       " 'api': 252,\n",
       " 'apmp': 253,\n",
       " 'appearance': 254,\n",
       " 'appetite': 255,\n",
       " 'appleoptometry': 256,\n",
       " 'applicable': 257,\n",
       " 'applicant': 258,\n",
       " 'applicants': 259,\n",
       " 'application': 260,\n",
       " 'applications': 261,\n",
       " 'applied': 262,\n",
       " 'applies': 263,\n",
       " 'apply': 264,\n",
       " 'applying': 265,\n",
       " 'appoint': 266,\n",
       " 'appointed': 267,\n",
       " 'appointment': 268,\n",
       " 'appointments': 269,\n",
       " 'appraisal': 270,\n",
       " 'appraisals': 271,\n",
       " 'appraising': 272,\n",
       " 'appreciation': 273,\n",
       " 'apprentice': 274,\n",
       " 'apprenticeship': 275,\n",
       " 'approach': 276,\n",
       " 'approachable': 277,\n",
       " 'approaches': 278,\n",
       " 'appropriately': 279,\n",
       " 'approval': 280,\n",
       " 'approved': 281,\n",
       " 'approx': 282,\n",
       " 'approximately': 283,\n",
       " 'aptitude': 284,\n",
       " 'aptrack': 285,\n",
       " 'ar': 286,\n",
       " 'architect': 287,\n",
       " 'architects': 288,\n",
       " 'architectural': 289,\n",
       " 'architecture': 290,\n",
       " 'architectures': 291,\n",
       " 'archiving': 292,\n",
       " 'area': 293,\n",
       " 'areas': 294,\n",
       " 'arena': 295,\n",
       " 'arise': 296,\n",
       " 'arisen': 297,\n",
       " 'arm': 298,\n",
       " 'armed': 299,\n",
       " 'arrange': 300,\n",
       " 'arranged': 301,\n",
       " 'arrangement': 302,\n",
       " 'arrangements': 303,\n",
       " 'arranging': 304,\n",
       " 'array': 305,\n",
       " 'arrow': 306,\n",
       " 'art': 307,\n",
       " 'articulate': 308,\n",
       " 'articulating': 309,\n",
       " 'artists': 310,\n",
       " 'asap': 311,\n",
       " 'asbestos': 312,\n",
       " 'ascertain': 313,\n",
       " 'ascot': 314,\n",
       " 'asda': 315,\n",
       " 'ashby': 316,\n",
       " 'ashford': 317,\n",
       " 'ashley': 318,\n",
       " 'asia': 319,\n",
       " 'asic': 320,\n",
       " 'asked': 321,\n",
       " 'asp': 322,\n",
       " 'aspect': 323,\n",
       " 'aspects': 324,\n",
       " 'aspirations': 325,\n",
       " 'aspire': 326,\n",
       " 'aspireinc': 327,\n",
       " 'assembler': 328,\n",
       " 'assemblies': 329,\n",
       " 'assembly': 330,\n",
       " 'assertive': 331,\n",
       " 'assess': 332,\n",
       " 'assessed': 333,\n",
       " 'assessing': 334,\n",
       " 'assessment': 335,\n",
       " 'assessments': 336,\n",
       " 'assessor': 337,\n",
       " 'assessors': 338,\n",
       " 'asset': 339,\n",
       " 'assets': 340,\n",
       " 'assigned': 341,\n",
       " 'assignment': 342,\n",
       " 'assignments': 343,\n",
       " 'assimilate': 344,\n",
       " 'assist': 345,\n",
       " 'assistance': 346,\n",
       " 'assistant': 347,\n",
       " 'assistants': 348,\n",
       " 'assisted': 349,\n",
       " 'assisting': 350,\n",
       " 'assists': 351,\n",
       " 'associate': 352,\n",
       " 'associates': 353,\n",
       " 'association': 354,\n",
       " 'assume': 355,\n",
       " 'assuming': 356,\n",
       " 'assumptions': 357,\n",
       " 'assurance': 358,\n",
       " 'assured': 359,\n",
       " 'astute': 360,\n",
       " 'ate': 361,\n",
       " 'atmosphere': 362,\n",
       " 'att': 363,\n",
       " 'attached': 364,\n",
       " 'attend': 365,\n",
       " 'attendance': 366,\n",
       " 'attending': 367,\n",
       " 'attention': 368,\n",
       " 'attitude': 369,\n",
       " 'attitudes': 370,\n",
       " 'attract': 371,\n",
       " 'attracting': 372,\n",
       " 'attractive': 373,\n",
       " 'attracts': 374,\n",
       " 'attributes': 375,\n",
       " 'audi': 376,\n",
       " 'audience': 377,\n",
       " 'audiences': 378,\n",
       " 'audio': 379,\n",
       " 'audit': 380,\n",
       " 'auditing': 381,\n",
       " 'auditor': 382,\n",
       " 'auditors': 383,\n",
       " 'audits': 384,\n",
       " 'authorisation': 385,\n",
       " 'authorised': 386,\n",
       " 'authorities': 387,\n",
       " 'authority': 388,\n",
       " 'authorized': 389,\n",
       " 'autism': 390,\n",
       " 'auto': 391,\n",
       " 'autocad': 392,\n",
       " 'autodesk': 393,\n",
       " 'automated': 394,\n",
       " 'automatic': 395,\n",
       " 'automatically': 396,\n",
       " 'automation': 397,\n",
       " 'automotive': 398,\n",
       " 'autonomous': 399,\n",
       " 'autonomously': 400,\n",
       " 'autonomy': 401,\n",
       " 'auxiliaries': 402,\n",
       " 'auxiliary': 403,\n",
       " 'av': 404,\n",
       " 'availability': 405,\n",
       " 'avenues': 406,\n",
       " 'average': 407,\n",
       " 'avon': 408,\n",
       " 'avse': 409,\n",
       " 'award': 410,\n",
       " 'awarded': 411,\n",
       " 'awards': 412,\n",
       " 'awardwinning': 413,\n",
       " 'aware': 414,\n",
       " 'awareness': 415,\n",
       " 'ax': 416,\n",
       " 'axapta': 417,\n",
       " 'axis': 418,\n",
       " 'aylesbury': 419,\n",
       " 'ba': 420,\n",
       " 'bachelor': 421,\n",
       " \"bachelor's\": 422,\n",
       " 'back': 423,\n",
       " 'backed': 424,\n",
       " 'backend': 425,\n",
       " 'background': 426,\n",
       " 'backgrounds': 427,\n",
       " 'backing': 428,\n",
       " 'backtesting': 429,\n",
       " 'backup': 430,\n",
       " 'bacs': 431,\n",
       " 'badenoch': 432,\n",
       " 'bailey': 433,\n",
       " 'baking': 434,\n",
       " 'balance': 435,\n",
       " 'balances': 436,\n",
       " 'band': 437,\n",
       " 'bank': 438,\n",
       " 'banking': 439,\n",
       " 'banks': 440,\n",
       " 'barchester': 441,\n",
       " \"barchester's\": 442,\n",
       " 'barns': 443,\n",
       " 'barnsley': 444,\n",
       " 'barry': 445,\n",
       " 'base': 446,\n",
       " 'baseband': 447,\n",
       " 'based': 448,\n",
       " 'basel': 449,\n",
       " 'bases': 450,\n",
       " 'basic': 451,\n",
       " 'basingstoke': 452,\n",
       " 'basis': 453,\n",
       " 'batch': 454,\n",
       " 'bath': 455,\n",
       " 'bathing': 456,\n",
       " 'bathroom': 457,\n",
       " 'bathrooms': 458,\n",
       " 'bdm': 459,\n",
       " 'beacon': 460,\n",
       " 'bearings': 461,\n",
       " 'beautiful': 462,\n",
       " 'becky': 463,\n",
       " 'bed': 464,\n",
       " 'bedded': 465,\n",
       " 'bedford': 466,\n",
       " 'bedfordshire': 467,\n",
       " 'beds': 468,\n",
       " 'began': 469,\n",
       " 'begin': 470,\n",
       " 'behalf': 471,\n",
       " 'behaviour': 472,\n",
       " 'behavioural': 473,\n",
       " 'behaviours': 474,\n",
       " 'belfast': 475,\n",
       " 'belief': 476,\n",
       " 'believes': 477,\n",
       " 'bell': 478,\n",
       " 'belt': 479,\n",
       " 'ben': 480,\n",
       " 'bench': 481,\n",
       " 'beneficial': 482,\n",
       " 'beneficiaries': 483,\n",
       " 'benefit': 484,\n",
       " 'benefits': 485,\n",
       " 'benelux': 486,\n",
       " 'beng': 487,\n",
       " 'benn': 488,\n",
       " 'bens': 489,\n",
       " 'berkshire': 490,\n",
       " 'bespoke': 491,\n",
       " 'beverage': 492,\n",
       " 'bexhill': 493,\n",
       " 'bi': 494,\n",
       " 'bias': 495,\n",
       " 'biased': 496,\n",
       " 'bid': 497,\n",
       " 'bids': 498,\n",
       " 'big': 499,\n",
       " 'biggest': 500,\n",
       " 'bikes': 501,\n",
       " 'billing': 502,\n",
       " 'billinghay': 503,\n",
       " 'billion': 504,\n",
       " 'bills': 505,\n",
       " 'biology': 506,\n",
       " 'birmingham': 507,\n",
       " 'birthdays': 508,\n",
       " 'bit': 509,\n",
       " 'black': 510,\n",
       " 'blackburn': 511,\n",
       " 'blake': 512,\n",
       " 'blind': 513,\n",
       " 'blocked': 514,\n",
       " 'blood': 515,\n",
       " 'bls': 516,\n",
       " 'blue': 517,\n",
       " 'bluebird': 518,\n",
       " 'bluechip': 519,\n",
       " 'bluestones': 520,\n",
       " 'bms': 521,\n",
       " 'bmsbmsit': 522,\n",
       " 'bmsgraduates': 523,\n",
       " 'bmsit': 524,\n",
       " 'bmsuk': 525,\n",
       " 'bn': 526,\n",
       " 'board': 527,\n",
       " 'boast': 528,\n",
       " 'boasts': 529,\n",
       " 'bodies': 530,\n",
       " 'body': 531,\n",
       " 'boiler': 532,\n",
       " 'boilers': 533,\n",
       " 'bolting': 534,\n",
       " 'bonus': 535,\n",
       " 'bonuses': 536,\n",
       " 'book': 537,\n",
       " 'booked': 538,\n",
       " 'booking': 539,\n",
       " 'bookings': 540,\n",
       " 'bookkeeper': 541,\n",
       " 'bookkeeping': 542,\n",
       " 'books': 543,\n",
       " 'boost': 544,\n",
       " 'border': 545,\n",
       " 'boring': 546,\n",
       " 'boss': 547,\n",
       " 'boundaries': 548,\n",
       " 'bournemouth': 549,\n",
       " 'boutique': 550,\n",
       " 'box': 551,\n",
       " 'boxes': 552,\n",
       " 'brace': 553,\n",
       " 'bracknell': 554,\n",
       " 'bradford': 555,\n",
       " 'brain': 556,\n",
       " 'branch': 557,\n",
       " 'branches': 558,\n",
       " 'brand': 559,\n",
       " 'branded': 560,\n",
       " 'brands': 561,\n",
       " 'brbrjob': 562,\n",
       " 'break': 563,\n",
       " 'breakdown': 564,\n",
       " 'breakdowns': 565,\n",
       " 'breaking': 566,\n",
       " 'breheny': 567,\n",
       " 'brian': 568,\n",
       " 'briant': 569,\n",
       " 'bridge': 570,\n",
       " 'briefing': 571,\n",
       " 'briefings': 572,\n",
       " 'briefs': 573,\n",
       " 'bright': 574,\n",
       " 'brighton': 575,\n",
       " 'brilliant': 576,\n",
       " 'bring': 577,\n",
       " 'bringing': 578,\n",
       " 'brings': 579,\n",
       " 'bristol': 580,\n",
       " 'britain': 581,\n",
       " \"britain's\": 582,\n",
       " 'british': 583,\n",
       " 'brixton': 584,\n",
       " 'broad': 585,\n",
       " 'broaden': 586,\n",
       " 'broken': 587,\n",
       " 'broker': 588,\n",
       " 'brokerage': 589,\n",
       " 'brokers': 590,\n",
       " 'broking': 591,\n",
       " 'bromley': 592,\n",
       " 'broughton': 593,\n",
       " 'brown': 594,\n",
       " 'brsalary': 595,\n",
       " 'bs': 596,\n",
       " 'bsc': 597,\n",
       " 'bubble': 598,\n",
       " 'buckinghamshire': 599,\n",
       " 'buckle': 600,\n",
       " 'budget': 601,\n",
       " 'budgetary': 602,\n",
       " 'budgeted': 603,\n",
       " 'budgeting': 604,\n",
       " 'budgets': 605,\n",
       " 'bug': 606,\n",
       " 'build': 607,\n",
       " 'building': 608,\n",
       " 'buildings': 609,\n",
       " 'builds': 610,\n",
       " 'built': 611,\n",
       " 'bulk': 612,\n",
       " 'bull': 613,\n",
       " 'bullability': 614,\n",
       " 'bupa': 615,\n",
       " 'bureau': 616,\n",
       " 'bureaux': 617,\n",
       " 'burgess': 618,\n",
       " 'burscough': 619,\n",
       " 'bury': 620,\n",
       " 'bus': 621,\n",
       " 'business': 622,\n",
       " 'businesses': 623,\n",
       " 'busy': 624,\n",
       " 'butler': 625,\n",
       " 'button': 626,\n",
       " 'buy': 627,\n",
       " 'buyer': 628,\n",
       " 'buyers': 629,\n",
       " 'buying': 630,\n",
       " 'buyside': 631,\n",
       " 'buytolet': 632,\n",
       " 'bydwragedd': 633,\n",
       " 'bydwreigiaeth': 634,\n",
       " 'ca': 635,\n",
       " 'cable': 636,\n",
       " 'cabling': 637,\n",
       " 'cad': 638,\n",
       " 'cadstar': 639,\n",
       " 'cae': 640,\n",
       " 'calco': 641,\n",
       " 'calculation': 642,\n",
       " 'calculations': 643,\n",
       " 'calculus': 644,\n",
       " 'calibrating': 645,\n",
       " 'calibration': 646,\n",
       " 'calibre': 647,\n",
       " 'california': 648,\n",
       " 'call': 649,\n",
       " 'called': 650,\n",
       " 'caller': 651,\n",
       " 'calling': 652,\n",
       " 'calls': 653,\n",
       " 'calm': 654,\n",
       " 'cam': 655,\n",
       " 'cambridge': 656,\n",
       " 'cambridgeshire': 657,\n",
       " 'cameras': 658,\n",
       " 'camhs': 659,\n",
       " 'campaign': 660,\n",
       " 'campaigns': 661,\n",
       " 'canada': 662,\n",
       " 'cancer': 663,\n",
       " 'candidate': 664,\n",
       " 'candidates': 665,\n",
       " 'cannock': 666,\n",
       " 'canteen': 667,\n",
       " 'canvassing': 668,\n",
       " 'capabilities': 669,\n",
       " 'capability': 670,\n",
       " 'capable': 671,\n",
       " 'capacity': 672,\n",
       " 'capex': 673,\n",
       " 'capita': 674,\n",
       " 'capital': 675,\n",
       " 'capture': 676,\n",
       " 'car': 677,\n",
       " 'carbon': 678,\n",
       " 'carcraft': 679,\n",
       " 'card': 680,\n",
       " 'cardiac': 681,\n",
       " 'cardiff': 682,\n",
       " 'cardiology': 683,\n",
       " 'cards': 684,\n",
       " 'care': 685,\n",
       " 'cared': 686,\n",
       " 'career': 687,\n",
       " 'careers': 688,\n",
       " 'carefully': 689,\n",
       " 'carer': 690,\n",
       " 'carers': 691,\n",
       " 'cares': 692,\n",
       " 'caribbean': 693,\n",
       " 'carillion': 694,\n",
       " 'carillon': 695,\n",
       " 'caring': 696,\n",
       " 'carl': 697,\n",
       " 'caroline': 698,\n",
       " 'carpet': 699,\n",
       " 'carpets': 700,\n",
       " 'carried': 701,\n",
       " 'carrier': 702,\n",
       " 'carriers': 703,\n",
       " 'carries': 704,\n",
       " 'carry': 705,\n",
       " 'carrying': 706,\n",
       " 'cars': 707,\n",
       " 'cart': 708,\n",
       " 'case': 709,\n",
       " 'caseload': 710,\n",
       " 'cases': 711,\n",
       " 'casework': 712,\n",
       " 'cash': 713,\n",
       " 'cashflow': 714,\n",
       " 'cashier': 715,\n",
       " 'cashiering': 716,\n",
       " 'castings': 717,\n",
       " 'casual': 718,\n",
       " 'casualty': 719,\n",
       " 'catalyst': 720,\n",
       " 'categories': 721,\n",
       " 'catering': 722,\n",
       " 'caterpillar': 723,\n",
       " 'caters': 724,\n",
       " 'catia': 725,\n",
       " 'ccab': 726,\n",
       " 'ccn': 727,\n",
       " 'cct': 728,\n",
       " 'cctv': 729,\n",
       " 'cduttoncompassltd': 730,\n",
       " 'celebrating': 731,\n",
       " 'celesio': 732,\n",
       " 'cell': 733,\n",
       " 'cells': 734,\n",
       " 'cellular': 735,\n",
       " 'cemap': 736,\n",
       " 'ceng': 737,\n",
       " 'central': 738,\n",
       " 'centrally': 739,\n",
       " 'centre': 740,\n",
       " \"centre's\": 741,\n",
       " 'centred': 742,\n",
       " 'centres': 743,\n",
       " 'century': 744,\n",
       " 'ceo': 745,\n",
       " 'cerebral': 746,\n",
       " 'certificate': 747,\n",
       " 'certificates': 748,\n",
       " 'certification': 749,\n",
       " 'certifications': 750,\n",
       " 'certified': 751,\n",
       " 'certus': 752,\n",
       " 'cfo': 753,\n",
       " 'chain': 754,\n",
       " 'chains': 755,\n",
       " 'chairing': 756,\n",
       " 'challenge': 757,\n",
       " 'challenges': 758,\n",
       " 'challenging': 759,\n",
       " 'champion': 760,\n",
       " 'chance': 761,\n",
       " 'change': 762,\n",
       " 'changed': 763,\n",
       " 'changing': 764,\n",
       " 'channel': 765,\n",
       " 'channels': 766,\n",
       " 'character': 767,\n",
       " 'characteristics': 768,\n",
       " 'charge': 769,\n",
       " 'charged': 770,\n",
       " 'charismatic': 771,\n",
       " 'charitable': 772,\n",
       " 'charities': 773,\n",
       " 'charity': 774,\n",
       " 'chartered': 775,\n",
       " 'charterhouse': 776,\n",
       " 'chartership': 777,\n",
       " 'chase': 778,\n",
       " 'chasemedical': 779,\n",
       " 'chat': 780,\n",
       " 'check': 781,\n",
       " 'checkable': 782,\n",
       " 'checking': 783,\n",
       " 'checks': 784,\n",
       " 'chelmsford': 785,\n",
       " 'cheltenham': 786,\n",
       " 'chemical': 787,\n",
       " 'cheques': 788,\n",
       " 'cheshire': 789,\n",
       " 'chester': 790,\n",
       " 'chesterfield': 791,\n",
       " 'chi': 792,\n",
       " 'chichester': 793,\n",
       " 'chief': 794,\n",
       " 'child': 795,\n",
       " \"child's\": 796,\n",
       " 'childcare': 797,\n",
       " 'children': 798,\n",
       " \"children's\": 799,\n",
       " 'chip': 800,\n",
       " 'choice': 801,\n",
       " 'choices': 802,\n",
       " 'choose': 803,\n",
       " 'chosen': 804,\n",
       " 'chris': 805,\n",
       " 'christmas': 806,\n",
       " 'church': 807,\n",
       " 'chwefror': 808,\n",
       " 'cima': 809,\n",
       " 'cinema': 810,\n",
       " 'circa': 811,\n",
       " 'circuit': 812,\n",
       " 'circuitry': 813,\n",
       " 'circuits': 814,\n",
       " 'circumstances': 815,\n",
       " 'cis': 816,\n",
       " 'cisco': 817,\n",
       " 'citizen': 818,\n",
       " 'citizens': 819,\n",
       " 'city': 820,\n",
       " 'civil': 821,\n",
       " 'civils': 822,\n",
       " 'claims': 823,\n",
       " 'clarity': 824,\n",
       " 'clark': 825,\n",
       " 'class': 826,\n",
       " 'classes': 827,\n",
       " 'classification': 828,\n",
       " 'clean': 829,\n",
       " 'cleaning': 830,\n",
       " 'cleanliness': 831,\n",
       " 'clear': 832,\n",
       " 'clearance': 833,\n",
       " 'cleared': 834,\n",
       " 'clerical': 835,\n",
       " 'clerk': 836,\n",
       " 'click': 837,\n",
       " 'clicking': 838,\n",
       " 'client': 839,\n",
       " \"client's\": 840,\n",
       " 'clientfacing': 841,\n",
       " 'clients': 842,\n",
       " 'climate': 843,\n",
       " 'climb': 844,\n",
       " 'climbing': 845,\n",
       " 'clinic': 846,\n",
       " 'clinical': 847,\n",
       " 'clinically': 848,\n",
       " 'clinicians': 849,\n",
       " 'clinics': 850,\n",
       " 'close': 851,\n",
       " 'closed': 852,\n",
       " 'closely': 853,\n",
       " 'closer': 854,\n",
       " 'closes': 855,\n",
       " 'closing': 856,\n",
       " 'clothing': 857,\n",
       " 'cloud': 858,\n",
       " 'club': 859,\n",
       " 'clustering': 860,\n",
       " 'cmc': 861,\n",
       " 'cmm': 862,\n",
       " \"cmm's\": 863,\n",
       " 'cms': 864,\n",
       " 'cnc': 865,\n",
       " 'coach': 866,\n",
       " 'coaching': 867,\n",
       " 'code': 868,\n",
       " 'coded': 869,\n",
       " 'codes': 870,\n",
       " 'coding': 871,\n",
       " 'coen': 872,\n",
       " 'colchester': 873,\n",
       " 'cold': 874,\n",
       " 'coldcalling': 875,\n",
       " 'collaborating': 876,\n",
       " 'collaboration': 877,\n",
       " 'colleague': 878,\n",
       " 'colleagues': 879,\n",
       " 'collect': 880,\n",
       " 'collected': 881,\n",
       " 'collection': 882,\n",
       " 'collections': 883,\n",
       " 'college': 884,\n",
       " 'colour': 885,\n",
       " 'combat': 886,\n",
       " 'combination': 887,\n",
       " 'combine': 888,\n",
       " 'combined': 889,\n",
       " 'comfort': 890,\n",
       " 'comfortable': 891,\n",
       " 'comforting': 892,\n",
       " 'coming': 893,\n",
       " 'comm': 894,\n",
       " 'command': 895,\n",
       " 'commence': 896,\n",
       " 'commensurate': 897,\n",
       " 'commentary': 898,\n",
       " 'commercial': 899,\n",
       " 'commercially': 900,\n",
       " 'commission': 901,\n",
       " 'commissioning': 902,\n",
       " 'commissions': 903,\n",
       " 'commit': 904,\n",
       " 'commited': 905,\n",
       " 'commitment': 906,\n",
       " 'commitments': 907,\n",
       " 'committed': 908,\n",
       " 'committee': 909,\n",
       " 'commodities': 910,\n",
       " 'commodity': 911,\n",
       " 'common': 912,\n",
       " 'comms': 913,\n",
       " 'communal': 914,\n",
       " 'communicate': 915,\n",
       " 'communicated': 916,\n",
       " 'communicating': 917,\n",
       " 'communication': 918,\n",
       " 'communications': 919,\n",
       " 'communicator': 920,\n",
       " 'community': 921,\n",
       " 'commutable': 922,\n",
       " 'commute': 923,\n",
       " 'companies': 924,\n",
       " 'companionship': 925,\n",
       " 'company': 926,\n",
       " \"company's\": 927,\n",
       " 'comparable': 928,\n",
       " 'compass': 929,\n",
       " 'compassionate': 930,\n",
       " 'compatibility': 931,\n",
       " 'compelling': 932,\n",
       " 'compensation': 933,\n",
       " 'competence': 934,\n",
       " 'competencies': 935,\n",
       " 'competency': 936,\n",
       " 'competent': 937,\n",
       " 'competently': 938,\n",
       " 'competition': 939,\n",
       " 'competitive': 940,\n",
       " 'competitor': 941,\n",
       " 'competitors': 942,\n",
       " 'compile': 943,\n",
       " 'compiling': 944,\n",
       " 'complaint': 945,\n",
       " 'complaints': 946,\n",
       " 'complement': 947,\n",
       " 'complete': 948,\n",
       " 'completed': 949,\n",
       " 'completely': 950,\n",
       " 'completeness': 951,\n",
       " 'completing': 952,\n",
       " 'completion': 953,\n",
       " 'complex': 954,\n",
       " 'complexity': 955,\n",
       " 'compliance': 956,\n",
       " 'compliant': 957,\n",
       " 'complied': 958,\n",
       " 'complies': 959,\n",
       " 'comply': 960,\n",
       " 'complying': 961,\n",
       " 'component': 962,\n",
       " 'components': 963,\n",
       " 'composite': 964,\n",
       " 'comprehension': 965,\n",
       " 'comprehensive': 966,\n",
       " 'compressed': 967,\n",
       " 'compressors': 968,\n",
       " 'computational': 969,\n",
       " 'computations': 970,\n",
       " 'computer': 971,\n",
       " 'computerised': 972,\n",
       " 'concentrate': 973,\n",
       " 'concentration': 974,\n",
       " 'concept': 975,\n",
       " 'concepts': 976,\n",
       " 'conceptual': 977,\n",
       " 'concern': 978,\n",
       " 'concerned': 979,\n",
       " 'concerns': 980,\n",
       " 'concise': 981,\n",
       " 'conclusion': 982,\n",
       " 'condition': 983,\n",
       " 'conditioning': 984,\n",
       " 'conditions': 985,\n",
       " 'conduct': 986,\n",
       " 'conducted': 987,\n",
       " 'conducting': 988,\n",
       " 'conduit': 989,\n",
       " 'confederation': 990,\n",
       " 'conference': 991,\n",
       " 'conferences': 992,\n",
       " 'confidence': 993,\n",
       " 'confident': 994,\n",
       " 'confidential': 995,\n",
       " 'confidentiality': 996,\n",
       " 'confidently': 997,\n",
       " 'configuration': 998,\n",
       " 'confirm': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_vocab(vocab_file):\n",
    "    vocab = {}\n",
    "    with open(vocab_file) as f:\n",
    "        for line in f:\n",
    "            (word, index) = line.split(':')\n",
    "            vocab[word.strip()] = int(index)\n",
    "    return vocab\n",
    "\n",
    "# Generates the w_index:word dictionary\n",
    "voc_fname = 'vocab.txt'\n",
    "voc_dict = read_vocab(voc_fname)\n",
    "voc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the `doc_wordweights` function takes the tfijob_ad document vector file, as well as the w_index:word dictionary, creates the mapping between w_index and the actual word, and creates a dictionary of word:weight or each unique word appear in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "4759",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tfijob_ad_weights\n\u001b[1;32m     14\u001b[0m fName_tVectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjobAd_tVector.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 15\u001b[0m tfijob_ad_weights \u001b[38;5;241m=\u001b[39m \u001b[43mdoc_wordweights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfName_tVectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoc_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36mdoc_wordweights\u001b[0;34m(fName_tVectors, voc_dict)\u001b[0m\n\u001b[1;32m      8\u001b[0m     weights \u001b[38;5;241m=\u001b[39m tv\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# list of 'word_index:weight' entries\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     weights \u001b[38;5;241m=\u001b[39m [w\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m weights] \u001b[38;5;66;03m# change the format of weight to a list of '[word_index,weight]' entries\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     wordweight_dict \u001b[38;5;241m=\u001b[39m {voc_dict[\u001b[38;5;28mint\u001b[39m(w[\u001b[38;5;241m0\u001b[39m])]:w[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m weights} \u001b[38;5;66;03m# construct the weight dictionary, where each entry is 'word:weight'\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     tfijob_ad_weights\u001b[38;5;241m.\u001b[39mappend(wordweight_dict) \n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tfijob_ad_weights\n",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m     weights \u001b[38;5;241m=\u001b[39m tv\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# list of 'word_index:weight' entries\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     weights \u001b[38;5;241m=\u001b[39m [w\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m weights] \u001b[38;5;66;03m# change the format of weight to a list of '[word_index,weight]' entries\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     wordweight_dict \u001b[38;5;241m=\u001b[39m {\u001b[43mvoc_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m:w[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m weights} \u001b[38;5;66;03m# construct the weight dictionary, where each entry is 'word:weight'\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     tfijob_ad_weights\u001b[38;5;241m.\u001b[39mappend(wordweight_dict) \n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tfijob_ad_weights\n",
      "\u001b[0;31mKeyError\u001b[0m: 4759"
     ]
    }
   ],
   "source": [
    "def doc_wordweights(fName_tVectors, voc_dict):\n",
    "    tfijob_ad_weights = [] # a list to store the  word:weight dictionaries of documents\n",
    "    \n",
    "    with open(fName_tVectors) as tVecf: \n",
    "        tVectors = tVecf.read().splitlines() # each line is a tfijob_ad vector representation of a document in string format 'word_index:weight word_index:weight .......'\n",
    "    for tv in tVectors: # for each tfijob_ad document vector\n",
    "        tv = tv.strip()\n",
    "        weights = tv.split(' ') # list of 'word_index:weight' entries\n",
    "        weights = [w.split(':') for w in weights] # change the format of weight to a list of '[word_index,weight]' entries\n",
    "        wordweight_dict = {voc_dict[int(w[0])]:w[1] for w in weights} # construct the weight dictionary, where each entry is 'word:weight'\n",
    "        tfijob_ad_weights.append(wordweight_dict) \n",
    "    return tfijob_ad_weights\n",
    "\n",
    "fName_tVectors = 'jobAd_tVector.txt'\n",
    "tfijob_ad_weights = doc_wordweights(fName_tVectors, voc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfijob_ad_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# take a look at the tfijob_ad word weights dictionary of the first document\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtfijob_ad_weights\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfijob_ad_weights' is not defined"
     ]
    }
   ],
   "source": [
    "# take a look at the tfijob_ad word weights dictionary of the first document\n",
    "tfijob_ad_weights[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, once we have the word:weight dictionary of each document, now we can construct the tf-ijob_ad weighted document embeddings. \n",
    "* the following `gen_docVecs` function is an revision/extension of the previous written function, that takes the word embeddings dictionary, the tokenized text of articles, and the tfijob_ad weights (list of word:weight dictionaries, one for each article) as arguments, and generates the document embeddings:\n",
    " 1. creates an empty dataframe `docs_vectors` to store the document embeddings of articles\n",
    "  2. it loop through every tokenized text:\n",
    "    - creates an empty dataframe `temp` to store all the word embeddings of the article\n",
    "    - for each word that exists in the word embeddings dictionary/keyedvectors, \n",
    "        - if the argument `tfijob_ad` weights are empty `[]`, it sets the weight of the word as 1\n",
    "        - otherwise, retrieve the weight of the word from the corresponding word:weight dictionary of the article from  `tfijob_ad`\n",
    "    - row bind the weighted word embedding to `temp`\n",
    "    - takes the sum of each column to create the document vector, i.e., the embedding of an article\n",
    "    - append the created document vector to the list of document vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extended version of the `gen_docVecs` function\n",
    "def gen_docVecs(wv,tk_txts,tfijob_ad = []): # generate vector representation for documents\n",
    "    docs_vectors = pd.DataFrame() # creating empty final dataframe\n",
    "    #stopwords = nltk.corpus.stopwords.words('english') # removing stop words\n",
    "\n",
    "    for i in range(0,len(tk_txts)):\n",
    "        tokens = list(set(tk_txts[i])) # get the list of distinct words of the document\n",
    "\n",
    "        temp = pd.DataFrame()  # creating a temporary dataframe(store value for 1st doc & for 2nd doc remove the details of 1st & proced through 2nd and so on..)\n",
    "        for w_ind in range(0, len(tokens)): # looping through each word of a single document and spliting through space\n",
    "            try:\n",
    "                word = tokens[w_ind]\n",
    "                word_vec = wv[word] # if word is present in embeddings(goole provides weights associate with words(300)) then proceed\n",
    "                \n",
    "                if tfijob_ad != []:\n",
    "                    word_weight = float(tfijob_ad[i][word])\n",
    "                else:\n",
    "                    word_weight = 1\n",
    "                temp = temp.append(pd.Series(word_vec*word_weight), ignore_index = True) # if word is present then append it to temporary dataframe\n",
    "            except:\n",
    "                pass\n",
    "        doc_vector = temp.sum() # take the sum of each column(w0, w1, w2,........w300)\n",
    "        docs_vectors = docs_vectors.append(doc_vector, ignore_index = True) # append each document value to the final dataframe\n",
    "    return docs_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok we now have everything ready to generate the weight document embeddings. \n",
    "We can do this on any of our previous explored models, including the pretrained Word2Vec GoogleNews300, Glove, our in-house trained Word2Vec and FastText.\n",
    "\n",
    "Let's generated the weighted version of the document embedding vectors first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_preTW2v_dvs = gen_docVecs(preTW2v_wv,job_ad['Tokenized Description'],tfijob_ad_weights)\n",
    "weighted_preTGloVe_dvs = gen_docVecs(preTGloVe_wv,job_ad['Tokenized Description'],tfijob_ad_weights)\n",
    "weighted_bbcW2v_dvs = gen_docVecs(bbcW2v_wv,job_ad['Tokenized Description'],tfijob_ad_weights)\n",
    "weighted_bbcFT_dvs = gen_docVecs(bbcFT_wv,job_ad['Tokenized Description'],tfijob_ad_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can do very much the same thing as what we do before for other models. \n",
    "Here, we will do this as loops, for each model:\n",
    "- we plot out the feature vectors  projected in a 2-dimensional space,then \n",
    "- we build the logistic regression model for document classfication and report the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "seed = 0\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "models = [weighted_preTW2v_dvs,weighted_preTGloVe_dvs,weighted_bbcW2v_dvs,weighted_bbcFT_dvs]\n",
    "model_names = [\"Weighted Pretrained Word2Vec\", \"Weighted Pretrained GloVe\", \"Weighted In-house Word2Vec\",\"Weighted In-house FastText\"]\n",
    "for i in range(0,len(models)): #loop through each model\n",
    "    dv = models[i]\n",
    "    name = model_names[i]\n",
    "    features = dv.to_numpy() # convert the dataframe stored features to an numpy array\n",
    "    print(name + \": tSNE 2 dimensional projected Feature space\")\n",
    "    plotTSNE(job_ad['Category'],features)\n",
    "    \n",
    "    # creating training and test split\n",
    "    X_train, X_test, y_train, y_test,train_indices,test_indices = train_test_split(dv, job_ad['Category'], list(range(0,len(job_ad))),test_size=0.33, random_state=seed)\n",
    "\n",
    "    model = LogisticRegression(max_iter = 2000,random_state=seed)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Accuracy: \", model.score(X_test, y_test))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Creating tfijob_ad weighted document embeddings using Gensim\n",
    "\n",
    "In the previous sections, we tried very hard to create the tfijob_ad weighted document embeddings using the generated tf-ijob_ad weights save in previous activity. \n",
    "Indeed, we can using Genism to do this direction, and it's indeed, a bit less effor required ðŸ˜‘ Will show you below. \n",
    "We will use the in-house build Word2Vec model as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.tfijob_admodel import Tfijob_adModel\n",
    "\n",
    "# we have two vocabularies here, one from the in-house bulit Word2Vec, the other from the articles \n",
    "# note that althought the Word2Vec is built on the same dataset, but they might have done further \n",
    "# pre-processing during model build (e.g., setting min_count), and thus, might create mismatch in the two vocabularis. \n",
    "# therefore, we remove tokenized words that doesn't exist in the keyedvectors in the Word2Vec keyedvectors\n",
    "processed_text = [[w for w in t if w in bbcW2v_wv.index_to_key] for t in job_ad['Tokenized Description']] \n",
    "\n",
    "# use the Gensim package to create a dictionary that encapsulates the mapping between normalized words and their integer ids.\n",
    "docs_dict = Dictionary(processed_text) # creates a dictionary from the text\n",
    "docs_dict.filter_extremes(no_below=5) # filtering words that appear less than 5 times\n",
    "docs_dict.compactify() # assign new word ids to all words, shrinking any gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what are the words that been get rid off when we do the fliter\n",
    "[w for w in bbcW2v_wv.index_to_key if w not in docs_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process yields a vocabulary with 8647 words. \n",
    "Then we use Gensim again to create a bag-of-words representation of each document, i.e., the TF-Ijob_ad vector for each document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.matutils import sparse2full\n",
    "\n",
    "docs_corpus = [docs_dict.doc2bow(doc) for doc in job_ad['Tokenized Description']] # convert corpus to Bag of Word format\n",
    "model_tfijob_ad = Tfijob_adModel(docs_corpus, id2word=docs_dict) # fit the tfijob_ad model\n",
    "# apply model to the list of corpus document, \n",
    "# so each document is a list of tuples, (word_index, weight) for each word appears in the document\n",
    "docs_tfijob_ad  = model_tfijob_ad[docs_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see for example, the tfijob_ad weights of the words in the 2nd document\n",
    "docs_tfijob_ad[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then transfer `docs_tfijob_ad` to matrix form. `vstack` function from numpy can stack arrays in sequence vertically (row wise), and `sparse2full` function convert a document in sparse document format (in size of the number of words in the document) into a dense numpy array (of size of the vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_vecs   = np.vstack([sparse2full(c, len(docs_dict)) for c in docs_tfijob_ad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_vecs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result, `docs_vecs`, is a matrix with 2225 rows (docs) and 8647 columns (TF-Ijob_ad terms). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the performance of this TF-Ijob_ad vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training and test split\n",
    "X_train, X_test, y_train, y_test,train_indices,test_indices = train_test_split(docs_vecs, job_ad['Category'], list(range(0,len(job_ad))),test_size=0.33, random_state=seed)\n",
    "\n",
    "model = LogisticRegression(max_iter = 1000,random_state=seed)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow~ quite good!\n",
    "\n",
    "Now try to use this tfijob_ad vector to create the weighted document embeddings.\n",
    "\n",
    "Be careful, the vocabulary are different, for instance, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how many words are encoded in our in-house Word2Vec model?\n",
    "len(bbcW2v_wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how about the tfijob_ad vector?\n",
    "len(docs_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only care about words that are in both vocabulary. \n",
    "In the following, we creates the word embeddings arrays for words exists in docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_vecs = np.vstack([bbcW2v_wv[docs_dict[i]] for i in range(len(docs_dict)) if docs_dict[i] in bbcW2v_wv.index_to_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_vecs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do the dot product of the two vectors and get our tfijob_ad weighted document embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfijob_ad_docs_emb = np.dot(docs_vecs, word_emb_vecs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training and test split\n",
    "X_train, X_test, y_train, y_test,train_indices,test_indices = train_test_split(tfijob_ad_docs_emb, job_ad['Category'], list(range(0,len(job_ad))),test_size=0.33, random_state=seed)\n",
    "\n",
    "model = LogisticRegression(max_iter = 1000,random_state=seed)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much difference from the one we did ourselves (refer to the performance of the `Weighted In-house Word2Vec`.\n",
    "Comparing the performance of the tfijob_ad weighted document emeddings with our in-house built Word2Vec and the non-weighted on (referring to Section 2), adding the tfijob_ad weight indeed worsen the results in this example. \n",
    "Indeed, in this example, the most simply bag-of-word tfijob_ad vector representatino words much better, i.e., 0.978 accuracy ðŸ˜†\n",
    "\n",
    "> **Discussion**\n",
    "Does adding the tfijob_ad weight to construct document embedding and/or having a more complicated model guarantees higher performance?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! ðŸ¤© It gets the right class (I hope you got the same, but maybe you have different results....)\n",
    "Try as many as you want and have fun! ðŸ˜Š\n",
    "\n",
    "If you run the infer_vecotr multiple time, every time you get a different vector. and thus, when you predict the class based on the different document vectors, you may get different results. ðŸ¤ª ðŸ¤ª ðŸ¤ª \n",
    "Refer to the answer of the [this question](https://github.com/RaRe-Technologies/gensim/wiki/recipes-&-faq#q12-ive-used-doc2vec-infer_vector-on-a-single-text-but-the-resulting-vector-is-different-each-time-is-there-a-bug-or-have-i-made-a-mistake-doc2vec-inference-non-determinism) to understand why. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Phew~~ this is a big activity. I got exhausted written it up and I believe you got a bit exhaused looking through it too ðŸ¤£\n",
    "Give yourself a clap! Well done! ðŸ‘ðŸ‘ðŸ‘\n",
    "\n",
    "\n",
    "\n",
    "## Exericse:\n",
    "Ok, we leave a few exercises for you:\n",
    "- We have try vector size 100 so far, but there are many alternatives, e.g., 50,200,300. Try other size and report performance. Discuss and share your thoughts with your peers: does larger vector size guarantees better performance?\n",
    "- So far, in this activities, we have been using the cleaned articles. Many of these libraries (including Genism) has included functionalities to do simply cleaning of text. Try them on and compare the performance.\n",
    "- Oh, one other very important thing. The results we presented so for in this activity, are based on a single run. To report more robust results, you should do Cross validation. Implement cross validation on the models we explore in this activity, and do a comprehensive comparsion on them.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] [TFIjob_ad with Word Embeddings](https://github.com/ytnvj2/DocumentEmbedding/blob/master/TFIjob_adwithEmbeddings.ipynb)  \n",
    "[2] [Problem-solving with ML: automatic document classification](https://cloud.google.com/blog/products/ai-machine-learning/problem-solving-with-ml-automatic-document-classification)     \n",
    "[3] [Creating TF-Ijob_ad Weighted Word Embeddings](http://dsgeek.com/2018/02/19/tfijob_ad_vectors.html)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
